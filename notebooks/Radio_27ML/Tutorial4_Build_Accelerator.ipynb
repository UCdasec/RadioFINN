{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Modulation with FINN - Notebook #4 of 5\n",
    "This notebook walks you through simple usage of FINN tools. FINN provides users with many tools to perform inference of quantized neural networks on FPGAs. Users could either design their own dataflow-style architechture for their own customized network, or use a template dataflow builder designed by FINN that works with many common type of neural network. \n",
    "\n",
    "Because our model (VGG10) is compatible with the template builder that FINN provide, we do not need to design our own dataflow architechture. We can use their template, with a few minor additional steps to handle our 1D convolutional layers.\n",
    "\n",
    "An example of an dataflow style structure going from a training a Brevitas model to running the bitfile on FPGA: [End-to-end flow](https://finn.readthedocs.io/en/latest/end_to_end_flow.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN Dataflow Architechture\n",
    "From here, we will setup a FINN's standard builder, with a few custom transformations, and export a bitfile which can be run using pynq on the FPGA.\n",
    "\n",
    "Original version of the code below can be found here: [Original version](https://github.com/Xilinx/finn-examples/blob/main/build/vgg10-radioml/build.py)\n",
    "\n",
    "Further information about setting up a builder for transformations can be found here: [Tutorial](https://github.com/Xilinx/finn/blob/main/notebooks/end2end_example/cybersecurity/3-build-accelerator-with-finn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom steps for the builder\n",
    "The builder has a few steps already prepared for us. However, since we are using a 1D conv layer, we will need to add 2 more custom steps to convert them from 1D to 2D. FINN works with 4D (NHWC) internally, even with feature maps with only 1 spatial dimension.\n",
    "\n",
    "`step_pre_streamline` is for converting from our model from 3D tensors to 4D tensors. This is because we initially use 1D convolutional layers. This means the input shape will be changed from `1x2x1024` to `1x2x1024x1`\n",
    "\n",
    "`step_convert_final_layers` is for converting the final layers (linear and topK) to hardware layers\n",
    "\n",
    "The code below is from the following finn example: [CustomSteps](https://github.com/Xilinx/finn-examples/blob/main/build/vgg10-radioml/custom_steps.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.builder.build_dataflow_config import DataflowBuildConfig\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "from finn.util.basic import alveo_default_platform\n",
    "\n",
    "def step_pre_streamline(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
    "    model = model.transform(Change3DTo4DTensors())\n",
    "    model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "    return model\n",
    "\n",
    "\n",
    "def step_convert_final_layers(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
    "    model = model.transform(to_hw.InferChannelwiseLinearLayer())\n",
    "    model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Dataflow Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the ONNX model and the target platform\n",
    "\n",
    "In this example:\n",
    "- We will use the `tidy.onnx` model that has just gone through the `network-surgery` from previous step (`notebook 3/5`)\n",
    "- The only target platform we will be using for this example is `ZCU104` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "dt=datetime.today().strftime('%Y_%m_%d')\n",
    "#Get the tidy.onnx model\n",
    "model_name='radio_27ml_tidy'\n",
    "#include date and random hex code to avoid duplicate file when output \n",
    "final_name=model_name+\"_\"+dt+\"_\"+os.urandom(3).hex()+\"/\"\n",
    "model_file = '27ml_rf/models/radio_27ml_tidy.onnx'\n",
    "\n",
    "# which platforms to build the networks for\n",
    "zynq_platforms = [\"ZCU104\"]\n",
    "alveo_platforms = []\n",
    "platforms_to_build = zynq_platforms + alveo_platforms\n",
    "\n",
    "# determine which shell flow to use for a given platform\n",
    "# Since we are using ZCU104, it should return VIVADO_ZYNQ\n",
    "def platform_to_shell(platform):\n",
    "    if platform in zynq_platforms:\n",
    "        return build_cfg.ShellFlowType.VIVADO_ZYNQ\n",
    "    elif platform in alveo_platforms:\n",
    "        return build_cfg.ShellFlowType.VITIS_ALVEO\n",
    "    else:\n",
    "        raise Exception(\"Unknown platform, can't determine ShellFlowType\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When FINN is building the bitfile, it will create multiple intermediate files that show the progress throughout the steps. These files will be stored in the directory which is assigned to the environment variable `FINN_BUILD_DIR`. \n",
    "\n",
    "For this example, we will create the `tmp/` in our workspace and assign to `FINN_BUILD_DIR` for easy access. \n",
    "\n",
    "In case the `tmp/` directory has already been generated, we will clear its content everytime we do a new run, so that we only keep the lastest intermediate files from that run.\n",
    "\n",
    "**Notice:** The `tmp/` directory is not commited onto our github repository to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp files will be built in /home/phu/repos/radio_finn_latest/RadioFINN/notebooks/Radio_27ML/tmp/\n",
      "removing old temp files in /home/phu/repos/radio_finn_latest/RadioFINN/notebooks/Radio_27ML/tmp/\n",
      "output will be generated in output/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "#Create a temporary folders (if none exist) to store intermediate transformations\n",
    "#This folder will be where all intermediate files generated by running VIVADO for synthesis\n",
    "finn_build_dir=os.getcwd()+'/tmp/'\n",
    "os.environ[\"FINN_BUILD_DIR\"]=finn_build_dir\n",
    "\n",
    "final_output_dir=\"output/\"\n",
    "Path(finn_build_dir).mkdir(exist_ok=True)\n",
    "Path(final_output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "#Remove all intermediate transformations from previous runs \n",
    "print(f'temp files will be built in {finn_build_dir}')\n",
    "print(f'removing old temp files in {finn_build_dir}')\n",
    "files = glob.glob(f'{finn_build_dir}*')\n",
    "for f in files:\n",
    "    if os.path.isdir(f):\n",
    "        shutil.rmtree(f)\n",
    "    elif os.path.isfile(f):\n",
    "        os.remove(f)\n",
    "\n",
    "\n",
    "print(f'output will be generated in {final_output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameters for the Dataflow Architechture.\n",
    "\n",
    "For this example, we define:\n",
    "1. `target fps`: Target inference performance in frames per second.\n",
    "2. `clock period`: Target clock period (in nanosecond) for Vivado synthesis.\n",
    "3. `select_build_steps`: The architechture of our build flow, going from the onnx model to the bitfile that can be run on FPGA.\n",
    "4. `select_generate_output`: What information about the product we want to see.\n",
    "    - Documentation on what the generated outputs mean: [Generated Outputs](https://finn.readthedocs.io/en/latest/command_line.html#generated-outputs)\n",
    "\n",
    "    \n",
    "Documentation for parameters can be found here: [BuildConfig](https://finn.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowBuildConfig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target inference performance in frames per second\n",
    "def select_target_fps(platform):\n",
    "    return 4500\n",
    "\n",
    "# Target clock period (in nanoseconds) for Vivado synthesis.\n",
    "# Frequency (MHz) = 1000 / clock_period_ns \n",
    "# e.g. synth_clk_period_ns=5.0 will target a 200 MHz clock.\n",
    "def select_clk_period(platform):\n",
    "    return 5.0 \n",
    "\n",
    "# assemble build flow from custom and pre-existing steps\n",
    "def select_build_steps(platform):\n",
    "    return [\n",
    "        #------------Network-Preparation------\n",
    "        \"step_tidy_up\",\n",
    "        step_pre_streamline, #Custom steps above\n",
    "        \"step_streamline\",\n",
    "        \"step_convert_to_hw\",\n",
    "        step_convert_final_layers,  #Custom steps above\n",
    "        \"step_create_dataflow_partition\",\n",
    "        \"step_specialize_layers\",\n",
    "        \"step_target_fps_parallelization\",\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_minimize_bit_width\",  \n",
    "        \"step_generate_estimate_reports\",\n",
    "        #------------Hardware-Build-(finn generate instruction files for VITIS HLS)----\n",
    "        \"step_hw_codegen\",\n",
    "        \"step_hw_ipgen\",\n",
    "        \"step_set_fifo_depths\",\n",
    "        \"step_create_stitched_ip\",\n",
    "        #------------HW-synthesis--------------------------\n",
    "        \"step_measure_rtlsim_performance\",\n",
    "        \"step_out_of_context_synthesis\",\n",
    "        \"step_synthesize_bitfile\",\n",
    "        \"step_make_pynq_driver\",\n",
    "        \"step_deployment_package\",\n",
    "    ]\n",
    "    \n",
    "#What information we want to see.\n",
    "def select_generate_output(platform):\n",
    "    return [\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.BITFILE, #This is how we tell the builder to generate the bitfile\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER, \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the `start_dataflow` function.\n",
    "- The input being the `platform_name`. In our example, this would be `ZCU104`\n",
    "- The function goes through 3 major steps:\n",
    "    1. Get the `release platform name`, `shell flow type`, and `vitis platform` and create a directory which will store its bitfile.\n",
    "    2. Set up a config for the builder based on the output from step 1.\n",
    "    3. Start running the architechture\n",
    "- The output is the `config file` and the `output directory`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_dataflow(platform_name):\n",
    "    '-----------------------Get the platform of the target board--------------------------'\n",
    "    shell_flow_type = platform_to_shell(platform_name)\n",
    "    if shell_flow_type == build_cfg.ShellFlowType.VITIS_ALVEO:\n",
    "        vitis_platform = alveo_default_platform[platform_name]\n",
    "        # for Alveo, use the Vitis platform name as the release name\n",
    "        # e.g. xilinx_u250_xdma_201830_2\n",
    "        release_platform_name = vitis_platform\n",
    "    else:\n",
    "        vitis_platform = None\n",
    "        # for Zynq, use the board name as the release name\n",
    "        # e.g. ZCU104\n",
    "        release_platform_name = platform_name\n",
    "    # platform_dir = \"release/%s\" % release_platform_name\n",
    "    # os.makedirs(platform_dir, exist_ok=True)\n",
    "    \n",
    "    '-----------------------Define the config for the build architechture---------------'\n",
    "    cfg = build_cfg.DataflowBuildConfig(\n",
    "        steps=select_build_steps(platform_name),\n",
    "        output_dir=final_output_dir+\"output_%s_%s\" % (final_name, release_platform_name),\n",
    "        synth_clk_period_ns=select_clk_period(platform_name),\n",
    "        target_fps=select_target_fps(platform_name), #Target FPS, not guaranteed the model will achieve\n",
    "        board=platform_name,\n",
    "        shell_flow_type=shell_flow_type,\n",
    "        vitis_platform=vitis_platform,\n",
    "        split_large_fifos=True,\n",
    "        standalone_thresholds=True,\n",
    "        # enable extra performance optimizations (physopt)\n",
    "        vitis_opt_strategy=build_cfg.VitisOptStrategyCfg.PERFORMANCE_BEST,\n",
    "        generate_outputs=select_generate_output(platform_name),        \n",
    "    )\n",
    "    \n",
    "    '-----------------------Start the build flow--------------------------------------------'\n",
    "    # Start the build flow, with the input being the [onnx model] and the [config file]\n",
    "    build.build_dataflow_cfg(model_file, cfg)\n",
    "    \n",
    "    return cfg#,platform_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize output files\n",
    "After running `start_dataflow()`, the output bitfile is generated, but can be tedious to find. \n",
    "This codes below will go look for the output files and copy them to the `release\\[platform_name]\\` directory\n",
    "\n",
    "`finn-accel.(bit|xclbin)`: generated Bitfile depending on the target platform\n",
    "\n",
    "`finn-accel.hwh`: generated Hardware Handoff File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_output_files(cfg):\n",
    "    # copy output deploy packages and rename bitfile\n",
    "    deploy_gen_dir = cfg.output_dir + \"/deploy\"\n",
    "    new_deploy_dir=\"deploy/\"+cfg.board+\"_\"+final_name\n",
    "    print('directory needed for FPGA: '+new_deploy_dir)\n",
    "    files_to_check_and_rename = [\n",
    "        \"finn-accel.bit\",\n",
    "        \"finn-accel.hwh\",\n",
    "        \"finn-accel.xclbin\",\n",
    "    ]\n",
    "    print(new_deploy_dir)\n",
    "    #copy output/[model]/deploy to /deploy\n",
    "    if os.path.exists(deploy_gen_dir):\n",
    "        shutil.copytree(deploy_gen_dir,new_deploy_dir)\n",
    "    Path(new_deploy_dir+'/datasets').mkdir()\n",
    "    shutil.copy(\"Tutorial5_Load_Bitsteam_on_FPGA.ipynb\",new_deploy_dir+\"/driver/\")\n",
    "    #rename all bit file to its model name for better readability\n",
    "    for f in files_to_check_and_rename:\n",
    "        src_file = new_deploy_dir + \"/\" + \"/bitfile/\"+f\n",
    "        new_file = src_file.replace(\"finn-accel\", final_name)\n",
    "        if os.path.isfile(src_file):\n",
    "            os.rename(src_file,new_file)\n",
    "            shutil.copy(new_file,new_deploy_dir+\"/driver/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start running the architechture\n",
    "We will iterate through all platform assigned in `platforms_to_build`, and run the dataflow architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZCU104']\n"
     ]
    }
   ],
   "source": [
    "print(platforms_to_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from 27ml_rf/models/radio_27ml_tidy.onnx\n",
      "Intermediate outputs will be generated in /home/phu/repos/radio_finn_latest/RadioFINN/notebooks/Radio_27ML/tmp/\n",
      "Final outputs will be generated in output/output_radio_27ml_tidy_2025_02_26_25d933/_ZCU104\n",
      "Build log is at output/output_radio_27ml_tidy_2025_02_26_25d933/_ZCU104/build_dataflow.log\n",
      "Running step: step_tidy_up [1/20]\n",
      "Running step: step_pre_streamline [2/20]\n",
      "Running step: step_streamline [3/20]\n",
      "Running step: step_convert_to_hw [4/20]\n",
      "Running step: step_convert_final_layers [5/20]\n",
      "Running step: step_create_dataflow_partition [6/20]\n",
      "Running step: step_specialize_layers [7/20]\n",
      "Running step: step_target_fps_parallelization [8/20]\n",
      "Running step: step_apply_folding_config [9/20]\n",
      "Running step: step_minimize_bit_width [10/20]\n",
      "Running step: step_generate_estimate_reports [11/20]\n",
      "Running step: step_hw_codegen [12/20]\n",
      "Running step: step_hw_ipgen [13/20]\n"
     ]
    }
   ],
   "source": [
    "# create a release dir, used for finn-examples release packaging\n",
    "os.makedirs(\"release\", exist_ok=True)\n",
    "\n",
    "# Iterate through all target platform\n",
    "# In this example, we only have 1 target platform (ZCU104)\n",
    "for platform_name in platforms_to_build:\n",
    "    \n",
    "    cfg=start_dataflow(platform_name)\n",
    "\n",
    "    organize_output_files(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have the generated bitfile, we can perform inference on the FPGA.\n",
    "\n",
    "1. <ins>First we need to zip the generated directory `deploy/[your platform+model]`. There are many ways to do it. Here we can do it in the terminal:</ins>\n",
    "\n",
    "```bash\n",
    "cd [path_to_deploy/]\n",
    "zip -r [zip_name].zip [name of folder needed zipping]\n",
    "```\n",
    "2. <ins>Then we can copy this zip file onto the FPGA. We can do that with the `scp` command</ins>\n",
    "\n",
    "```bash\n",
    "scp [/path/to/zip/file/you/want/to/copy] username@remoteaddress:[where/to/put/file/on/fpga]\n",
    "```\n",
    "3. <ins>On the FPGA, once we verify that zip file is copied, we can unzip it with the command on the FPGA terminal:</ins>\n",
    "\n",
    "```bash\n",
    "unzip [filename].zip -d [destination]\n",
    "```\n",
    "4. <ins>To run the notebook on the FPGA, we can run the following command on the FPGA terminal:</ins>\n",
    "\n",
    "```bash\n",
    "sudo -E jupyter lab -p 8888 --allow-root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About The Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange> **NOTE**: Do not remove all the generated files in `/tmp` yet. We will need them for running implemetation on VIVADO </font>\n",
    "\n",
    "\n",
    "### FINN Generated Reports\n",
    "Inside the generated output folder, (eg. `output/[model_name]/_ZCU104/report/`), there will be estimated reports generated by finn.\n",
    "\n",
    "Estimated performance (**throughput fps, latency in ns, node with highest cycle**, ...) can be found in __estimate_network_performance.json__\n",
    "\n",
    "### Run Implematation with VIVADO\n",
    "Aside from generated reports, we can also run implemetation on the generated VIVADO project of the model to get **LUT**, **FF** and **BRAM** utilization\n",
    "\n",
    "Ensure the final generated VIVADO project can be found in the `output/[model_name]/[platform]/stiched_ip/finn_vivado_stitch_proj.xpr`\n",
    "\n",
    "We can now open VIVADO, and open a project that has the path pointing at the `stich_proj.xpr` above.\n",
    "\n",
    "Once the project is opened, we can run synthesis and implementation on VIVADO, which will give us the **Utilization reports**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"ref_images\\VIVADO_run_implementation.png\" width=\"1200\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
