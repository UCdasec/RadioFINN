{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Modulation with FINN - Notebook #4 of 5\n",
    "This notebook walks you through the steps to use FINN to create a bitstream file for the FPGA! \n",
    "Specifically, we:\n",
    "1. Create IP/Verilog per layer (with Vitis HLS and IPI)\n",
    "2. Create a stitched design (with Vitis HLS and IPI)\n",
    "3. Create a Vivado project \n",
    "4. Run synthesis (to generate a bitfile) \n",
    "5. Generate the runtime driver (Python file which hold the model definition and communicate with PYNQ API to run inference on FPGA)\n",
    "\n",
    "### Cell Overview \n",
    "This notebook walks you through steps:\n",
    "1. Defining custom steps for the builder\n",
    "2. Setting up Dataflow Builder\n",
    "3. Build Artifacts\n",
    "4. Setting Parameters for the Dataflow Architechture.\n",
    "\n",
    "\n",
    "### FINN Pipeline Map\n",
    "Throughout these notebooks, you will begin to understand the FINN pipeline! In order the pipeline is:\n",
    "1. Dataset and Vanilla model\n",
    "2. Brevitas Model\n",
    "3. Transforming the Brevitas Model to tidy.onnx\n",
    "4. **Transforming tidy.onnx to bitstream** (you are here)\n",
    "5. Loading the bitstream on the FPGA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining custom steps for the builder\n",
    "Specifically, we use FINNs _builders_ to create a _dataflow-stype_ architecture. \n",
    "\n",
    "Because our model (VGG10) is compatible with the template builder that FINN provide, we do not need to design our own dataflow architechture. We can use their template, with a few minor additional steps to handle our 1D convolutional layers.\n",
    "\n",
    "A _builder_ can be thought of as a pseudo \"compiler toolchain\", but for compiling with a FPGA target!\n",
    "\n",
    "The _builder_ has a few steps already prepared for us. However, since we are using a 1D conv layer, we will need to add 2 more custom steps to convert them from 1D to 2D. FINN works with 4D (NHWC) internally, even with feature maps with only 1 spatial dimension.\n",
    "\n",
    "`step_pre_streamline` is for converting from our model from 3D tensors to 4D tensors. This is because we initially use 1D convolutional layers. This means the input shape will be changed from `1x2x1024` to `1x2x1024x1`\n",
    "\n",
    "`step_convert_final_layers` is for converting the final layers (linear and topK) to hardware layers\n",
    "\n",
    "The code below is from the following finn example: [CustomSteps](https://github.com/Xilinx/finn-examples/blob/main/build/vgg10-radioml/custom_steps.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.builder.build_dataflow_config import DataflowBuildConfig\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path \n",
    "\n",
    "\n",
    "def step_pre_streamline(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
    "    model = model.transform(Change3DTo4DTensors())\n",
    "    model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "    return model\n",
    "\n",
    "\n",
    "def step_convert_final_layers(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
    "    model = model.transform(to_hw.InferChannelwiseLinearLayer())\n",
    "    model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up Dataflow Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the ONNX model and the target platform\n",
    "\n",
    "In this example:\n",
    "- We will use the `finn.onnx` model that has just gone through the `network-surgery` from previous step (`notebook 3/5`)\n",
    "- The only target platform we will be using for this example is `ZCU104` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=datetime.today().strftime('%Y_%m_%d')\n",
    "#The output model_name, used for naming the output directory\n",
    "model_name = 'radio_27ml_finn_2bit'\n",
    "\n",
    "#include date and random hex code to avoid duplicate file when output \n",
    "final_name=model_name+\"_\"+dt+\"_\"+os.urandom(3).hex()+\"/\"\n",
    "#The onnx model that was previously generated by tutorial 3\n",
    "model_file ='27ml_rf_2bit(done)/onnx_models/radio_27ml_finn.onnx'\n",
    "\n",
    "# which platforms to build the networks for\n",
    "zynq_platform = \"ZCU104\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Artifacts \n",
    "\n",
    "When FINN is compiling the bitfile, many artifacts are generated. There are three important locations for artifacts:\n",
    "1. ***Temporary Artifacts:*** saved in \"notebooks/tmp\". In the below cell we set environment variable FINN_BUILD_DIR to this directory.\n",
    "2. ***Output Artifacts:*** saved in \"notebooks/output\". These include the Vivado project files that can be open in Vivado.\n",
    "3. ***Deploy Artifacts:*** saved in \"notebooks/deploy\". These are the files to be copied to the FPGA.\n",
    "\n",
    "**Temporary Artifacts** are _overwritten_ which each new run. These files are created by the FINN compiler. Specifically, in the tmp folder there are files generated for the coressponding HLS, RTL, and IP for layers.\n",
    "\n",
    "**Output Artifacts** Contain the Vivado project itself that can be open directly in Vivado. In total this contains (1) Bitfile (2) Intermediate Models (3) The stitched IP for the model (4) other configuation and log files. \n",
    "\n",
    "**Deploy Artifacts** Contain this the files to be copied to the FPGA. This contains (1) The bitfile (2) The driver python file to be ran on the FPGA. \n",
    "\n",
    "**Notice:** The `tmp/` directory is not commited onto our github repository to save space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing the old temporary artifacts at: tmp\n",
      "output will be generated in output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "#Define the temporary folders \n",
    "temporary_artifacts = Path('tmp')\n",
    "os.environ[\"FINN_BUILD_DIR\"]=str(temporary_artifacts.absolute())\n",
    "temporary_artifacts.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the Output Artifacts directory and create it \n",
    "output_dir= Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#Remove all intermediate transformations from previous runs \n",
    "print(f'Clearing the old temporary artifacts at: {temporary_artifacts}')\n",
    "shutil.rmtree(temporary_artifacts)\n",
    "\n",
    "print(f'output will be generated in {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting Parameters for the Dataflow Architechture.\n",
    "\n",
    "For this example, we define:\n",
    "1. `target fps`: Target inference performance in frames per second.\n",
    "2. `clock period`: Target clock period (in nanosecond) for Vivado synthesis.\n",
    "3. `select_build_steps`: The architechture of our build flow, going from the onnx model to the bitfile that can be run on FPGA.\n",
    "4. `select_generate_output`: What information about the product we want to see.\n",
    "    - Documentation on what the generated outputs mean: [Generated Outputs](https://finn.readthedocs.io/en/latest/command_line.html#generated-outputs)\n",
    "\n",
    "    \n",
    "Documentation for parameters can be found here: [BuildConfig](https://finn.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowBuildConfig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target inference performance in frames per second\n",
    "def select_target_fps(platform):\n",
    "    return 4500\n",
    "\n",
    "# Target clock period (in nanoseconds) for Vivado synthesis.\n",
    "# Frequency (MHz) = 1000 / clock_period_ns \n",
    "# e.g. synth_clk_period_ns=5.0 will target a 200 MHz clock.\n",
    "def select_clk_period(platform):\n",
    "    return 5.0 \n",
    "\n",
    "# assemble build flow from custom and pre-existing steps\n",
    "def select_build_steps(platform):\n",
    "    return [\n",
    "        #------------Network-Preparation------\n",
    "        \"step_tidy_up\",\n",
    "        step_pre_streamline, #Custom steps above\n",
    "        \"step_streamline\",\n",
    "        \"step_convert_to_hw\",\n",
    "        step_convert_final_layers,  #Custom steps above\n",
    "        \"step_create_dataflow_partition\",\n",
    "        \"step_specialize_layers\",\n",
    "        \"step_target_fps_parallelization\",\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_minimize_bit_width\",  \n",
    "        \"step_generate_estimate_reports\",\n",
    "        #------------Hardware-Build-(finn generate instruction files for VITIS HLS)----\n",
    "        \"step_hw_codegen\",\n",
    "        \"step_hw_ipgen\",\n",
    "        \"step_set_fifo_depths\",\n",
    "        \"step_create_stitched_ip\",\n",
    "        #------------HW-synthesis--------------------------\n",
    "        \"step_measure_rtlsim_performance\",\n",
    "        \"step_out_of_context_synthesis\",\n",
    "        \"step_synthesize_bitfile\",\n",
    "        \"step_make_pynq_driver\",\n",
    "        \"step_deployment_package\",\n",
    "    ]\n",
    "    \n",
    "#What information we want to see.\n",
    "def select_generate_output(platform):\n",
    "    return [\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.BITFILE, #This is how we tell the builder to generate the bitfile\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER, \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the `start_dataflow` function.\n",
    "- The input being the `platform_name`. In our example, this would be `ZCU104`\n",
    "- The function goes through 3 major steps:\n",
    "    1. Get the `release platform name`, `shell flow type`, and `vitis platform` and create a directory which will store its bitfile.\n",
    "    2. Set up a config for the builder based on the output from step 1.\n",
    "    3. Start running the architechture\n",
    "- The output is the `config file` and the `output directory`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_dataflow(platform_name, output_dir):\n",
    "    '-----------------------Get the platform of the target board--------------------------'\n",
    "    shell_flow_type = build_cfg.ShellFlowType.VIVADO_ZYNQ\n",
    "    vitis_platform = None\n",
    "    release_platform_name = platform_name\n",
    "\n",
    "    \n",
    "    '-----------------------Define the config for the build architechture---------------'\n",
    "    cfg = build_cfg.DataflowBuildConfig(\n",
    "        steps=select_build_steps(platform_name),\n",
    "        output_dir=str(output_dir.joinpath(f\"output_{final_name}_{release_platform_name}\")),\n",
    "        synth_clk_period_ns=select_clk_period(platform_name),\n",
    "        target_fps=select_target_fps(platform_name), #Target FPS, not guaranteed the model will achieve\n",
    "        board=platform_name,\n",
    "        shell_flow_type=shell_flow_type,\n",
    "        vitis_platform=vitis_platform,\n",
    "        split_large_fifos=True,\n",
    "        standalone_thresholds=True,\n",
    "        # enable extra performance optimizations (physopt)\n",
    "        vitis_opt_strategy=build_cfg.VitisOptStrategyCfg.PERFORMANCE_BEST,\n",
    "        generate_outputs=select_generate_output(platform_name),        \n",
    "    )\n",
    "    \n",
    "    '-----------------------Start the build flow--------------------------------------------'\n",
    "    # Start the build flow, with the input being the [onnx model] and the [config file]\n",
    "    build.build_dataflow_cfg(model_file, cfg)\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start running the architechture\n",
    "We will iterate through all platform assigned in `platforms_to_build`, and run the dataflow architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from 27ml_rf_2bit(done)/onnx_models/radio_27ml_finn.onnx\n",
      "Intermediate outputs will be generated in /home/phu/repos/RadioFINN/notebooks/tmp\n",
      "Final outputs will be generated in output/output_radio_27ml_finn_2bit_2025_07_17_c8f176/_ZCU104\n",
      "Build log is at output/output_radio_27ml_finn_2bit_2025_07_17_c8f176/_ZCU104/build_dataflow.log\n",
      "Running step: step_tidy_up [1/20]\n",
      "Running step: step_pre_streamline [2/20]\n",
      "Running step: step_streamline [3/20]\n",
      "Running step: step_convert_to_hw [4/20]\n",
      "Running step: step_convert_final_layers [5/20]\n",
      "Running step: step_create_dataflow_partition [6/20]\n",
      "Running step: step_specialize_layers [7/20]\n",
      "Running step: step_target_fps_parallelization [8/20]\n",
      "Running step: step_apply_folding_config [9/20]\n",
      "Running step: step_minimize_bit_width [10/20]\n",
      "Running step: step_generate_estimate_reports [11/20]\n",
      "Running step: step_hw_codegen [12/20]\n",
      "Running step: step_hw_ipgen [13/20]\n",
      "Running step: step_set_fifo_depths [14/20]\n",
      "Running step: step_create_stitched_ip [15/20]\n",
      "Running step: step_measure_rtlsim_performance [16/20]\n",
      "Running step: step_out_of_context_synthesis [17/20]\n",
      "Running step: step_synthesize_bitfile [18/20]\n",
      "Running step: step_make_pynq_driver [19/20]\n",
      "Running step: step_deployment_package [20/20]\n",
      "Completed successfully\n"
     ]
    }
   ],
   "source": [
    "cfg=start_dataflow(zynq_platform, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy dir is created at /home/phu/repos/RadioFINN/notebooks/deploy/ZCU104_radio_27ml_finn_2bit_2025_07_17_c8f176\n"
     ]
    }
   ],
   "source": [
    "#Create deploy dir\n",
    "def create_deploy_dir(cfg, final_name):\n",
    "    # copy output deploy packages and rename bitfile\n",
    "    original_deploy_dir = Path(cfg.output_dir).joinpath(\"deploy\") \n",
    "    new_deploy_dir= Path(\"deploy\").joinpath(f\"{cfg.board}_{final_name}\")\n",
    "    print(f'deploy dir is created at {new_deploy_dir.resolve()}')\n",
    "    # Define the files we are going to check for from the original deplay \n",
    "    # dir, and rename when we move to our deplay directory \n",
    "    files_to_check_and_rename = [\n",
    "        \"finn-accel.bit\",\n",
    "        \"finn-accel.hwh\",\n",
    "        \"finn-accel.xclbin\",\n",
    "    ]\n",
    "    \n",
    "    #copy output/[model]/deploy to /deploy\n",
    "    if original_deploy_dir.exists():\n",
    "        shutil.copytree(original_deploy_dir,new_deploy_dir, dirs_exist_ok=True)\n",
    "\n",
    "    shutil.copy(\"Tutorial5_Load_Bitstream_on_FPGA.ipynb\",new_deploy_dir.joinpath(\"driver\"))\n",
    "\n",
    "    for f in files_to_check_and_rename:\n",
    "        src_file = new_deploy_dir.joinpath(\"bitfile\").joinpath(f)\n",
    "        if src_file.is_file():\n",
    "            shutil.copy(src_file, new_deploy_dir.joinpath(\"driver\").joinpath(f))\n",
    "            \n",
    "create_deploy_dir(cfg, final_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The next tutorial notebook (Tutorial 5) is meant to be run on FPGA. The notebook is automatically copied in the deploy dir\n",
    "\n",
    "## Now that we have the generated bitfile, we can perform inference on the FPGA.\n",
    "\n",
    "First we need to zip the generated directory `deploy/[your_model]`. There are many ways to do it. Here we can do it in the terminal:\n",
    "\n",
    "To copy this notebook from you HOST machine to the FPGA and run ***on the fpga*** (substitute IP with the IP of the FPGA device)\n",
    "\n",
    "1. `scp -r deploy xilinx@IP:/home/xilinx`\n",
    "2. `ssh -L 8888:localhost:8888 xilinx@IP`\n",
    "3. `sudo -E jupyter notebook --port 8888` \n",
    "4. Click the URL generated by jupyter notebook to enter jupyter and select this script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About The Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange> **NOTE**: Do not remove all the generated files in `/tmp` yet. We will need them for running implemetation on VIVADO </font>\n",
    "\n",
    "\n",
    "### FINN Generated Reports\n",
    "Inside the generated output folder, (eg. `output/[model_name]/_ZCU104/report/`), there will be estimated reports generated by finn.\n",
    "\n",
    "Estimated performance (**throughput fps, latency in ns, node with highest cycle**, ...) can be found in __estimate_network_performance.json__\n",
    "\n",
    "### Run Implematation with VIVADO\n",
    "Aside from generated reports, we can also run implemetation on the generated VIVADO project of the model to get **LUT**, **FF** and **BRAM** utilization\n",
    "\n",
    "Ensure the final generated VIVADO project can be found in the `output/[model_name]/[platform]/stiched_ip/finn_vivado_stitch_proj.xpr`\n",
    "\n",
    "We can now open VIVADO, and open a project that has the path pointing at the `stich_proj.xpr` above.\n",
    "\n",
    "Once the project is opened, we can run synthesis and implementation on VIVADO by clicking `RUN SYNTHESIS` and then `RUN IMPLEMENTATION` on the left panel, which will give us the **Utilization reports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VIVADO_Overview](https://raw.githubusercontent.com/UCdasec/RadioFINN/refs/heads/main/ref_images/vivado_proj_overview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Check_Part_ID](https://raw.githubusercontent.com/UCdasec/RadioFINN/refs/heads/main/ref_images/vivado_proj_tutorial_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Utilization_Report](https://raw.githubusercontent.com/UCdasec/RadioFINN/refs/heads/main/ref_images/vivado_proj_tutorial_2.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
